{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package nps_chat to\n",
      "[nltk_data]     C:\\Users\\emiel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package nps_chat is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\emiel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\emiel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\emiel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'official'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [70]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mofficial\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnlp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optimization\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'official'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('nps_chat')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from official.nlp import optimization  # to create AdamW optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = nltk.corpus.nps_chat.xml_posts()\n",
    "X = [post.text for post in posts]\n",
    "y  = ['question' if (post.get('class') == 'whQuestion' or post.get('class') == 'ynQuestion') else \"other\" for post in posts]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK Naive Bayes Classifier\n",
    "\n",
    "++ easy to understand\n",
    "\n",
    "-- ignores word order / context (\"is this it\" is the same as \"this is it\") confuses statements and questions\n",
    "\n",
    "-- huge reliance on signal words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8731060606060606\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def dialogue_act_features(post):\n",
    "    features = {}\n",
    "    for word in nltk.word_tokenize(post):\n",
    "        features['contains({})'.format(word.lower())] = True\n",
    "    return features\n",
    "\n",
    "\n",
    "featuresets = [(dialogue_act_features(post.text), target) for post, target in list(zip(posts,y))]\n",
    "size = int(len(featuresets) * 0.1)\n",
    "train_set, test_set = featuresets[size:], featuresets[:size]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accept',\n",
       " 'Bye',\n",
       " 'Clarify',\n",
       " 'Continuer',\n",
       " 'Emotion',\n",
       " 'Emphasis',\n",
       " 'Greet',\n",
       " 'Other',\n",
       " 'Reject',\n",
       " 'Statement',\n",
       " 'System',\n",
       " 'nAnswer',\n",
       " 'whQuestion',\n",
       " 'yAnswer',\n",
       " 'ynQuestion'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([post.get('class') for post in posts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             contains(?) = True           questi : other  =     59.5 : 1.0\n",
      "           contains(wtf) = True           questi : other  =     56.8 : 1.0\n",
      "         contains(whats) = True           questi : other  =     54.6 : 1.0\n",
      "       contains(anybody) = True           questi : other  =     44.8 : 1.0\n",
      "           contains(asl) = True           questi : other  =     44.8 : 1.0\n",
      "            contains(tx) = True           questi : other  =     32.9 : 1.0\n",
      "         contains(which) = True           questi : other  =     32.9 : 1.0\n",
      "           contains(who) = True           questi : other  =     31.1 : 1.0\n",
      "          contains(part) = True            other : questi =     30.0 : 1.0\n",
      "          contains(doin) = True           questi : other  =     26.9 : 1.0\n",
      "        contains(purple) = True           questi : other  =     26.9 : 1.0\n",
      "           contains(how) = True           questi : other  =     25.0 : 1.0\n",
      "        contains(anyone) = True           questi : other  =     23.4 : 1.0\n",
      "          contains(sang) = True           questi : other  =     23.3 : 1.0\n",
      "           contains(why) = True           questi : other  =     21.3 : 1.0\n",
      "contains(11-06-adultsuser88) = True           questi : other  =     20.9 : 1.0\n",
      "            contains(23) = True           questi : other  =     20.9 : 1.0\n",
      "           contains(amy) = True           questi : other  =     20.9 : 1.0\n",
      "          contains(lose) = True           questi : other  =     20.9 : 1.0\n",
      "          contains(mary) = True           questi : other  =     20.9 : 1.0\n",
      "         contains(nakey) = True           questi : other  =     20.9 : 1.0\n",
      "        contains(number) = True           questi : other  =     20.9 : 1.0\n",
      "          contains(ohio) = True           questi : other  =     20.9 : 1.0\n",
      "        contains(silver) = True           questi : other  =     20.9 : 1.0\n",
      "      contains(supposed) = True           questi : other  =     20.9 : 1.0\n",
      "      contains(yourself) = True           questi : other  =     20.9 : 1.0\n",
      "           contains(any) = True           questi : other  =     17.8 : 1.0\n",
      "          contains(what) = True           questi : other  =     16.8 : 1.0\n",
      "         contains(where) = True           questi : other  =     16.5 : 1.0\n",
      "          contains(whos) = True           questi : other  =     16.1 : 1.0\n",
      "           contains(huh) = True           questi : other  =     15.9 : 1.0\n",
      "contains(11-08-adultsuser59) = True           questi : other  =     14.9 : 1.0\n",
      "contains(11-08-teensuser22) = True           questi : other  =     14.9 : 1.0\n",
      "contains(11-09-20suser53) = True           questi : other  =     14.9 : 1.0\n",
      "        contains(booted) = True           questi : other  =     14.9 : 1.0\n",
      "         contains(burns) = True           questi : other  =     14.9 : 1.0\n",
      "         contains(chick) = True           questi : other  =     14.9 : 1.0\n",
      "       contains(college) = True           questi : other  =     14.9 : 1.0\n",
      "           contains(frm) = True           questi : other  =     14.9 : 1.0\n",
      "            contains(gf) = True           questi : other  =     14.9 : 1.0\n",
      "        contains(guitar) = True           questi : other  =     14.9 : 1.0\n",
      "     contains(holocaust) = True           questi : other  =     14.9 : 1.0\n",
      "        contains(island) = True           questi : other  =     14.9 : 1.0\n",
      "        contains(living) = True           questi : other  =     14.9 : 1.0\n",
      "        contains(moving) = True           questi : other  =     14.9 : 1.0\n",
      "       contains(suppose) = True           questi : other  =     14.9 : 1.0\n",
      "         contains(texas) = True           questi : other  =     14.9 : 1.0\n",
      "     contains(wisconsin) = True           questi : other  =     14.9 : 1.0\n",
      "           contains(won) = True           questi : other  =     14.9 : 1.0\n",
      "contains(11-06-adultsuser35) = True           questi : other  =     12.5 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question\n"
     ]
    }
   ],
   "source": [
    "line = \"Do you enjoy high performance programming?\"\n",
    "print(classifier.classify(dialogue_act_features(line)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question\n"
     ]
    }
   ],
   "source": [
    "line = \"What do you think about high performance programming?\"\n",
    "print(classifier.classify(dialogue_act_features(line)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "other\n"
     ]
    }
   ],
   "source": [
    "line = \"i am testing this\"\n",
    "print(classifier.classify(dialogue_act_features(line)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small Bert\n",
    "https://www.tensorflow.org/text/tutorials/classify_text_with_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
      "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"
     ]
    }
   ],
   "source": [
    "bert_model_name = 'small_bert/bert_en_uncased_L-4_H-512_A-8' \n",
    "\n",
    "map_name_to_handle = {\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_base/2',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/google/electra_small/2',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/google/electra_base/2',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n",
    "}\n",
    "\n",
    "map_model_to_preprocess = {\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_preprocess/3',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "}\n",
    "\n",
    "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
    "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
    "\n",
    "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
    "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys       : ['input_type_ids', 'input_mask', 'input_word_ids']\n",
      "Shape      : (1, 128)\n",
      "Word Ids   : [ 101 2023 2003 2107 2019 6429 3185  999  102    0    0    0]\n",
      "Input Mask : [1 1 1 1 1 1 1 1 1 0 0 0]\n",
      "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "text_test = ['this is such an amazing movie!']\n",
    "text_preprocessed = bert_preprocess_model(text_test)\n",
    "\n",
    "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
    "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
    "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
    "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
    "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = hub.KerasLayer(tfhub_handle_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-pooled_output represents each input sequence as a whole. The shape is [batch_size, H]. You can think of this as an embedding for an entire movie review.\n",
    "\n",
    "-sequence_output represents each input token in the context. The shape is [batch_size, seq_length, H]. You can think of this as a contextual embedding for every token in a movie review.\n",
    "\n",
    "-encoder_outputs are the intermediate activations of the L Transformer blocks. outputs[\"encoder_outputs\"][i] is a Tensor of shape [batch_size, seq_length, 1024] with the outputs of the i-th Transformer block, for 0 <= i < L. The last value of the list is equal to sequence_output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pooled_output': <tf.Tensor: shape=(1, 512), dtype=float32, numpy=\n",
       " array([[ 7.62628675e-01,  9.92809832e-01, -1.86118230e-01,\n",
       "          3.66738409e-01,  1.52337253e-01,  6.55044198e-01,\n",
       "          9.68115389e-01, -9.48626995e-01,  2.16170028e-03,\n",
       "         -9.87773180e-01,  6.84268996e-02, -9.76305962e-01,\n",
       "          2.99959213e-01, -9.99825835e-01,  2.18229845e-01,\n",
       "          4.57803100e-01,  1.28510460e-01,  2.62946784e-01,\n",
       "         -4.03386146e-01, -1.70664459e-01,  1.30040094e-01,\n",
       "         -1.20208636e-01, -9.34154868e-01,  2.52415270e-01,\n",
       "          9.80566800e-01,  9.85106528e-01, -3.83478463e-01,\n",
       "         -6.19302541e-02,  3.53126884e-01,  9.61802304e-01,\n",
       "          4.37848449e-01, -7.62055591e-02,  3.83452266e-01,\n",
       "         -3.99953455e-01,  3.88874829e-01, -7.05698952e-02,\n",
       "         -1.84964299e-01, -3.74650687e-01, -8.90866458e-01,\n",
       "         -2.45328173e-01,  1.48198260e-02, -4.44235913e-02,\n",
       "          8.27980563e-02, -6.79375231e-01,  1.38857409e-01,\n",
       "         -9.11620408e-02, -9.95979846e-01,  2.31295705e-01,\n",
       "          2.47622773e-01, -3.34113926e-01,  9.97976124e-01,\n",
       "         -3.57810795e-01,  9.73542154e-01, -6.24328852e-01,\n",
       "          3.07091683e-01,  1.60280079e-01, -1.44826278e-01,\n",
       "         -1.74541101e-01, -9.99539196e-01, -9.98977661e-01,\n",
       "          9.33453590e-02, -2.23835930e-01,  9.98142064e-01,\n",
       "         -9.03366804e-02,  2.15027452e-01, -9.98293936e-01,\n",
       "         -9.93888825e-05,  7.61683643e-01,  9.14675519e-02,\n",
       "          8.81137922e-02,  9.83048558e-01,  9.94190872e-01,\n",
       "         -1.54018849e-01, -9.71209049e-01, -5.48703194e-01,\n",
       "          1.66939199e-01, -2.95076460e-01,  9.85258579e-01,\n",
       "         -1.94796517e-01, -2.55096525e-01, -9.84164834e-01,\n",
       "         -1.20104231e-01,  9.94991839e-01, -6.19593978e-01,\n",
       "          9.92243409e-01, -9.99621928e-01,  3.39152277e-01,\n",
       "          1.73366889e-01, -4.22022849e-01, -1.96295440e-01,\n",
       "         -9.92719769e-01, -1.32573560e-01,  5.47868848e-01,\n",
       "         -9.88404751e-01, -7.75913477e-01, -6.40167534e-01,\n",
       "          9.49923098e-01, -8.66907388e-02, -2.01916903e-01,\n",
       "         -3.64012301e-01, -5.82453191e-01, -8.21321905e-01,\n",
       "         -9.77031052e-01,  2.20602646e-01, -2.86966205e-01,\n",
       "          6.63212687e-02,  9.90430892e-01,  2.88470984e-01,\n",
       "         -5.31456530e-01,  4.80062902e-01, -2.04793662e-01,\n",
       "          4.23700958e-01,  9.88471210e-01, -9.96448934e-01,\n",
       "         -2.51451135e-01,  3.83189976e-01,  4.96087432e-01,\n",
       "          9.17864561e-01, -1.38056930e-04,  9.97011900e-01,\n",
       "         -9.83851552e-01,  7.47371912e-02, -9.89918888e-01,\n",
       "          9.26546037e-01, -3.78851920e-01, -1.50043592e-01,\n",
       "         -1.97118059e-01,  1.94223523e-01, -5.58378994e-02,\n",
       "         -2.55652875e-01,  9.94940579e-01,  9.98858988e-01,\n",
       "          9.68727887e-01,  2.58114398e-01,  4.80596572e-01,\n",
       "         -9.06892002e-01,  9.66376245e-01, -9.91291881e-01,\n",
       "         -5.39944112e-01,  3.43862087e-01,  9.99972880e-01,\n",
       "          4.13956106e-01, -6.25356376e-01,  6.28902078e-01,\n",
       "         -2.16055140e-01,  9.91671622e-01, -9.60305035e-01,\n",
       "          7.08349168e-01, -1.32944450e-01, -2.14211613e-01,\n",
       "         -4.86383066e-02, -3.06361049e-01,  9.70957220e-01,\n",
       "          1.59732729e-01,  2.91158706e-01, -2.12716639e-01,\n",
       "         -8.49497080e-01,  9.12066996e-01,  3.97582680e-01,\n",
       "          5.38035482e-02, -1.95851877e-01,  2.95858979e-01,\n",
       "         -4.26905453e-01, -6.73463345e-01,  9.99596655e-01,\n",
       "          2.33249906e-02, -2.91729301e-01, -4.49446261e-01,\n",
       "          9.97131109e-01,  5.44568479e-01,  1.20992757e-01,\n",
       "         -9.88504827e-01,  9.60839987e-01, -9.53754187e-01,\n",
       "          6.92339420e-01,  4.48572457e-01,  1.41910717e-01,\n",
       "          3.84909987e-01,  9.99748588e-01,  6.78024232e-01,\n",
       "          9.82405007e-01, -4.95666675e-02,  9.94555116e-01,\n",
       "         -8.79285097e-01,  7.96881437e-01, -9.80414808e-01,\n",
       "         -9.71916080e-01, -7.69297004e-01, -1.29525483e-01,\n",
       "          9.96294141e-01,  1.78358093e-01, -5.21232307e-01,\n",
       "         -9.99227226e-01, -5.26329279e-01,  9.99500930e-01,\n",
       "          2.99652874e-01, -8.71599257e-01, -9.94495094e-01,\n",
       "          9.43198681e-01,  2.34441489e-01,  3.92223150e-01,\n",
       "         -3.84546667e-01,  2.37304807e-01,  1.72320008e-01,\n",
       "         -5.35275877e-01,  9.49814320e-01, -3.85073960e-01,\n",
       "          9.62388396e-01,  9.95478511e-01,  2.95416713e-01,\n",
       "          3.17407697e-01,  4.58250612e-01, -1.40972152e-01,\n",
       "          1.79100454e-01,  9.92426336e-01, -9.38459218e-01,\n",
       "          9.27345693e-01,  9.66441691e-01,  9.78223562e-01,\n",
       "          1.14648923e-01, -9.90929544e-01, -5.89736342e-01,\n",
       "         -9.50371623e-01,  1.49873570e-01,  8.51662278e-01,\n",
       "          3.26818496e-01, -9.81222093e-01,  5.63782632e-01,\n",
       "         -9.95843470e-01,  9.79191959e-01, -8.95182192e-02,\n",
       "         -2.06956901e-02, -1.32529527e-01,  1.38085455e-01,\n",
       "          9.64455485e-01,  2.11848021e-01, -7.90156543e-01,\n",
       "          4.17950183e-01,  3.46748978e-01, -8.07007551e-02,\n",
       "          9.49249327e-01,  9.99973595e-01, -8.92258167e-01,\n",
       "          9.40616071e-01,  6.99490249e-01,  6.78396165e-01,\n",
       "          9.95642483e-01,  1.28700256e-01,  9.60242510e-01,\n",
       "          2.53915563e-02, -2.69453436e-01, -6.14463836e-02,\n",
       "         -6.54865742e-01,  5.25081992e-01,  9.90854919e-01,\n",
       "         -1.64652020e-01, -1.15863778e-01, -9.98729169e-01,\n",
       "          7.50907123e-01,  8.23737562e-01, -5.44667125e-01,\n",
       "         -9.94100034e-01, -4.19651479e-01, -6.45316303e-01,\n",
       "         -3.14368382e-02,  9.98141408e-01,  4.87910300e-01,\n",
       "         -8.65992546e-01,  1.45727485e-01,  1.87730074e-01,\n",
       "          9.98382688e-01,  1.46596223e-01, -9.86287177e-01,\n",
       "          9.99789417e-01, -3.91179919e-01, -9.91036534e-01,\n",
       "          9.95312333e-01,  6.41602874e-02, -9.08387303e-01,\n",
       "         -1.58141434e-01, -9.91545618e-01, -9.99215245e-01,\n",
       "          8.03015411e-01,  9.98973846e-01, -3.32495928e-01,\n",
       "         -8.42092261e-02,  3.73414069e-01,  2.70733833e-01,\n",
       "         -9.89446223e-01, -9.99516487e-01, -7.70957589e-01,\n",
       "          6.21771254e-02,  4.36927706e-01,  9.24941480e-01,\n",
       "          9.97540295e-01, -9.98088837e-01, -2.45038420e-01,\n",
       "          9.74303424e-01, -7.94605911e-02,  9.93370593e-01,\n",
       "          9.99450862e-01, -7.07644284e-01, -8.30895960e-01,\n",
       "          8.98295641e-01, -1.01530582e-01, -1.71470538e-01,\n",
       "          4.74043489e-01,  9.95530903e-01, -8.80121142e-02,\n",
       "          4.70759898e-01,  2.22401589e-01,  7.33649313e-01,\n",
       "         -7.37256780e-02,  7.59146214e-01,  8.12294304e-01,\n",
       "          1.41526952e-01,  3.76019239e-01,  3.39545101e-01,\n",
       "          5.80030620e-01,  9.99790370e-01, -1.79860085e-01,\n",
       "          1.99037984e-01, -4.69460160e-01,  8.70560884e-01,\n",
       "         -2.37593547e-01, -4.47979301e-01, -8.65355670e-01,\n",
       "          7.65121281e-01, -9.90383327e-01,  3.82324457e-01,\n",
       "          6.48539364e-01,  2.66881108e-01, -3.27811688e-01,\n",
       "          7.71422923e-01, -1.29253045e-01, -3.89292866e-01,\n",
       "          6.93512186e-02, -8.94340396e-01, -9.60046291e-01,\n",
       "          3.71892065e-01,  9.99563336e-01, -3.90957855e-02,\n",
       "         -4.88997817e-01,  9.90934789e-01, -2.67010957e-01,\n",
       "          9.82963204e-01,  8.56696844e-01,  9.99372423e-01,\n",
       "         -1.92579180e-01,  9.96981084e-01,  2.10357442e-01,\n",
       "          2.84461647e-01,  9.65796486e-02,  2.44745061e-01,\n",
       "          9.76513445e-01,  4.05047178e-01, -6.81259751e-01,\n",
       "         -1.93609908e-01, -4.84825373e-01,  2.30696306e-01,\n",
       "         -9.99203742e-01, -9.56096470e-01, -5.79378188e-01,\n",
       "         -3.96878719e-02, -5.73904365e-02, -9.74193513e-01,\n",
       "         -9.73427594e-01,  1.00152403e-01,  2.40723401e-01,\n",
       "          1.62927836e-01,  2.42329016e-01,  9.43726182e-01,\n",
       "         -6.38530925e-02,  1.26870483e-01, -7.18344271e-01,\n",
       "         -9.92574334e-01, -7.11851195e-02, -1.46030426e-01,\n",
       "         -4.83590335e-01, -6.13327205e-01,  7.13953257e-01,\n",
       "         -1.53984979e-01, -9.97635901e-01,  2.99064964e-01,\n",
       "          9.98741150e-01,  8.56169045e-01,  3.11263293e-01,\n",
       "         -4.50186342e-01,  9.73553658e-01, -2.72070616e-01,\n",
       "         -1.30773008e-01,  9.94025409e-01, -9.99943256e-01,\n",
       "         -8.85474831e-02, -3.88364613e-01, -8.56459066e-02,\n",
       "          1.23220183e-01, -4.03664529e-01,  9.99085486e-01,\n",
       "          2.30332427e-02, -4.24665600e-01, -9.42262888e-01,\n",
       "          3.93936455e-01, -1.33290095e-02,  9.59551990e-01,\n",
       "          1.57274175e-02, -9.25130963e-01, -1.93071008e-01,\n",
       "         -2.65474349e-01, -9.99908507e-01,  9.78813648e-01,\n",
       "          4.50990796e-01, -9.99000013e-01,  2.61028677e-01,\n",
       "         -6.55636370e-01,  5.67904711e-01,  1.85161486e-01,\n",
       "         -9.02370572e-01, -1.27932683e-01, -9.99364913e-01,\n",
       "         -4.35874581e-01,  9.97788668e-01, -3.16906035e-01,\n",
       "          9.62255776e-01,  2.90363550e-01, -9.50056553e-01,\n",
       "         -2.74001718e-01, -1.88334510e-02,  2.15329662e-01,\n",
       "          2.70551324e-01,  4.60419685e-01, -9.78495777e-01,\n",
       "          9.95513856e-01, -9.37972844e-01,  7.95150578e-01,\n",
       "          1.82261333e-01, -8.90303075e-01, -8.80954564e-01,\n",
       "         -3.77923965e-01,  7.56195188e-02, -3.23663235e-01,\n",
       "         -9.85925734e-01, -9.98959482e-01, -6.33480623e-02,\n",
       "         -9.98691916e-01, -8.01522672e-01, -9.85162437e-01,\n",
       "          2.47793660e-01, -4.02586132e-01,  1.03882305e-01,\n",
       "         -1.52591825e-01,  2.09507987e-01,  2.19178610e-02,\n",
       "          5.76247633e-01,  1.60194486e-01,  9.98519659e-01,\n",
       "         -4.26371694e-01, -2.99708366e-01, -3.94284010e-01,\n",
       "          9.93945837e-01,  8.77698898e-01,  1.11086354e-01,\n",
       "         -9.98374939e-01,  4.53648925e-01,  9.91885662e-01,\n",
       "          9.16699469e-01,  8.71488273e-01,  9.96536732e-01,\n",
       "         -9.29224253e-01, -1.06886543e-01,  3.26357573e-01,\n",
       "         -5.76192617e-01,  7.50882268e-01, -1.37595713e-01,\n",
       "          6.93647325e-01, -9.98303115e-01, -9.70150948e-01,\n",
       "         -3.42495926e-02, -9.87183750e-01,  9.42197144e-01,\n",
       "          3.47525597e-01,  2.69227415e-01,  4.51329857e-01,\n",
       "          3.19435328e-01, -2.51565367e-01, -8.42267096e-01,\n",
       "         -9.86535668e-01, -6.13613486e-01,  1.50642574e-01,\n",
       "         -3.69367182e-01, -1.50070548e-01, -9.99991119e-01,\n",
       "         -9.76706386e-01,  4.00266826e-01,  2.16104940e-01,\n",
       "          2.96440069e-02, -5.82243800e-02,  2.13437140e-01,\n",
       "         -8.18849206e-01,  9.99166787e-01, -8.80628645e-01,\n",
       "         -1.37993604e-01,  3.45505252e-02,  7.73416236e-02,\n",
       "          6.84458688e-02, -1.80267736e-01,  9.59138155e-01,\n",
       "          7.51162827e-01,  1.32814333e-01,  2.18579829e-01,\n",
       "         -4.58394796e-01, -2.02126484e-02]], dtype=float32)>,\n",
       " 'default': <tf.Tensor: shape=(1, 512), dtype=float32, numpy=\n",
       " array([[ 7.62628675e-01,  9.92809832e-01, -1.86118230e-01,\n",
       "          3.66738409e-01,  1.52337253e-01,  6.55044198e-01,\n",
       "          9.68115389e-01, -9.48626995e-01,  2.16170028e-03,\n",
       "         -9.87773180e-01,  6.84268996e-02, -9.76305962e-01,\n",
       "          2.99959213e-01, -9.99825835e-01,  2.18229845e-01,\n",
       "          4.57803100e-01,  1.28510460e-01,  2.62946784e-01,\n",
       "         -4.03386146e-01, -1.70664459e-01,  1.30040094e-01,\n",
       "         -1.20208636e-01, -9.34154868e-01,  2.52415270e-01,\n",
       "          9.80566800e-01,  9.85106528e-01, -3.83478463e-01,\n",
       "         -6.19302541e-02,  3.53126884e-01,  9.61802304e-01,\n",
       "          4.37848449e-01, -7.62055591e-02,  3.83452266e-01,\n",
       "         -3.99953455e-01,  3.88874829e-01, -7.05698952e-02,\n",
       "         -1.84964299e-01, -3.74650687e-01, -8.90866458e-01,\n",
       "         -2.45328173e-01,  1.48198260e-02, -4.44235913e-02,\n",
       "          8.27980563e-02, -6.79375231e-01,  1.38857409e-01,\n",
       "         -9.11620408e-02, -9.95979846e-01,  2.31295705e-01,\n",
       "          2.47622773e-01, -3.34113926e-01,  9.97976124e-01,\n",
       "         -3.57810795e-01,  9.73542154e-01, -6.24328852e-01,\n",
       "          3.07091683e-01,  1.60280079e-01, -1.44826278e-01,\n",
       "         -1.74541101e-01, -9.99539196e-01, -9.98977661e-01,\n",
       "          9.33453590e-02, -2.23835930e-01,  9.98142064e-01,\n",
       "         -9.03366804e-02,  2.15027452e-01, -9.98293936e-01,\n",
       "         -9.93888825e-05,  7.61683643e-01,  9.14675519e-02,\n",
       "          8.81137922e-02,  9.83048558e-01,  9.94190872e-01,\n",
       "         -1.54018849e-01, -9.71209049e-01, -5.48703194e-01,\n",
       "          1.66939199e-01, -2.95076460e-01,  9.85258579e-01,\n",
       "         -1.94796517e-01, -2.55096525e-01, -9.84164834e-01,\n",
       "         -1.20104231e-01,  9.94991839e-01, -6.19593978e-01,\n",
       "          9.92243409e-01, -9.99621928e-01,  3.39152277e-01,\n",
       "          1.73366889e-01, -4.22022849e-01, -1.96295440e-01,\n",
       "         -9.92719769e-01, -1.32573560e-01,  5.47868848e-01,\n",
       "         -9.88404751e-01, -7.75913477e-01, -6.40167534e-01,\n",
       "          9.49923098e-01, -8.66907388e-02, -2.01916903e-01,\n",
       "         -3.64012301e-01, -5.82453191e-01, -8.21321905e-01,\n",
       "         -9.77031052e-01,  2.20602646e-01, -2.86966205e-01,\n",
       "          6.63212687e-02,  9.90430892e-01,  2.88470984e-01,\n",
       "         -5.31456530e-01,  4.80062902e-01, -2.04793662e-01,\n",
       "          4.23700958e-01,  9.88471210e-01, -9.96448934e-01,\n",
       "         -2.51451135e-01,  3.83189976e-01,  4.96087432e-01,\n",
       "          9.17864561e-01, -1.38056930e-04,  9.97011900e-01,\n",
       "         -9.83851552e-01,  7.47371912e-02, -9.89918888e-01,\n",
       "          9.26546037e-01, -3.78851920e-01, -1.50043592e-01,\n",
       "         -1.97118059e-01,  1.94223523e-01, -5.58378994e-02,\n",
       "         -2.55652875e-01,  9.94940579e-01,  9.98858988e-01,\n",
       "          9.68727887e-01,  2.58114398e-01,  4.80596572e-01,\n",
       "         -9.06892002e-01,  9.66376245e-01, -9.91291881e-01,\n",
       "         -5.39944112e-01,  3.43862087e-01,  9.99972880e-01,\n",
       "          4.13956106e-01, -6.25356376e-01,  6.28902078e-01,\n",
       "         -2.16055140e-01,  9.91671622e-01, -9.60305035e-01,\n",
       "          7.08349168e-01, -1.32944450e-01, -2.14211613e-01,\n",
       "         -4.86383066e-02, -3.06361049e-01,  9.70957220e-01,\n",
       "          1.59732729e-01,  2.91158706e-01, -2.12716639e-01,\n",
       "         -8.49497080e-01,  9.12066996e-01,  3.97582680e-01,\n",
       "          5.38035482e-02, -1.95851877e-01,  2.95858979e-01,\n",
       "         -4.26905453e-01, -6.73463345e-01,  9.99596655e-01,\n",
       "          2.33249906e-02, -2.91729301e-01, -4.49446261e-01,\n",
       "          9.97131109e-01,  5.44568479e-01,  1.20992757e-01,\n",
       "         -9.88504827e-01,  9.60839987e-01, -9.53754187e-01,\n",
       "          6.92339420e-01,  4.48572457e-01,  1.41910717e-01,\n",
       "          3.84909987e-01,  9.99748588e-01,  6.78024232e-01,\n",
       "          9.82405007e-01, -4.95666675e-02,  9.94555116e-01,\n",
       "         -8.79285097e-01,  7.96881437e-01, -9.80414808e-01,\n",
       "         -9.71916080e-01, -7.69297004e-01, -1.29525483e-01,\n",
       "          9.96294141e-01,  1.78358093e-01, -5.21232307e-01,\n",
       "         -9.99227226e-01, -5.26329279e-01,  9.99500930e-01,\n",
       "          2.99652874e-01, -8.71599257e-01, -9.94495094e-01,\n",
       "          9.43198681e-01,  2.34441489e-01,  3.92223150e-01,\n",
       "         -3.84546667e-01,  2.37304807e-01,  1.72320008e-01,\n",
       "         -5.35275877e-01,  9.49814320e-01, -3.85073960e-01,\n",
       "          9.62388396e-01,  9.95478511e-01,  2.95416713e-01,\n",
       "          3.17407697e-01,  4.58250612e-01, -1.40972152e-01,\n",
       "          1.79100454e-01,  9.92426336e-01, -9.38459218e-01,\n",
       "          9.27345693e-01,  9.66441691e-01,  9.78223562e-01,\n",
       "          1.14648923e-01, -9.90929544e-01, -5.89736342e-01,\n",
       "         -9.50371623e-01,  1.49873570e-01,  8.51662278e-01,\n",
       "          3.26818496e-01, -9.81222093e-01,  5.63782632e-01,\n",
       "         -9.95843470e-01,  9.79191959e-01, -8.95182192e-02,\n",
       "         -2.06956901e-02, -1.32529527e-01,  1.38085455e-01,\n",
       "          9.64455485e-01,  2.11848021e-01, -7.90156543e-01,\n",
       "          4.17950183e-01,  3.46748978e-01, -8.07007551e-02,\n",
       "          9.49249327e-01,  9.99973595e-01, -8.92258167e-01,\n",
       "          9.40616071e-01,  6.99490249e-01,  6.78396165e-01,\n",
       "          9.95642483e-01,  1.28700256e-01,  9.60242510e-01,\n",
       "          2.53915563e-02, -2.69453436e-01, -6.14463836e-02,\n",
       "         -6.54865742e-01,  5.25081992e-01,  9.90854919e-01,\n",
       "         -1.64652020e-01, -1.15863778e-01, -9.98729169e-01,\n",
       "          7.50907123e-01,  8.23737562e-01, -5.44667125e-01,\n",
       "         -9.94100034e-01, -4.19651479e-01, -6.45316303e-01,\n",
       "         -3.14368382e-02,  9.98141408e-01,  4.87910300e-01,\n",
       "         -8.65992546e-01,  1.45727485e-01,  1.87730074e-01,\n",
       "          9.98382688e-01,  1.46596223e-01, -9.86287177e-01,\n",
       "          9.99789417e-01, -3.91179919e-01, -9.91036534e-01,\n",
       "          9.95312333e-01,  6.41602874e-02, -9.08387303e-01,\n",
       "         -1.58141434e-01, -9.91545618e-01, -9.99215245e-01,\n",
       "          8.03015411e-01,  9.98973846e-01, -3.32495928e-01,\n",
       "         -8.42092261e-02,  3.73414069e-01,  2.70733833e-01,\n",
       "         -9.89446223e-01, -9.99516487e-01, -7.70957589e-01,\n",
       "          6.21771254e-02,  4.36927706e-01,  9.24941480e-01,\n",
       "          9.97540295e-01, -9.98088837e-01, -2.45038420e-01,\n",
       "          9.74303424e-01, -7.94605911e-02,  9.93370593e-01,\n",
       "          9.99450862e-01, -7.07644284e-01, -8.30895960e-01,\n",
       "          8.98295641e-01, -1.01530582e-01, -1.71470538e-01,\n",
       "          4.74043489e-01,  9.95530903e-01, -8.80121142e-02,\n",
       "          4.70759898e-01,  2.22401589e-01,  7.33649313e-01,\n",
       "         -7.37256780e-02,  7.59146214e-01,  8.12294304e-01,\n",
       "          1.41526952e-01,  3.76019239e-01,  3.39545101e-01,\n",
       "          5.80030620e-01,  9.99790370e-01, -1.79860085e-01,\n",
       "          1.99037984e-01, -4.69460160e-01,  8.70560884e-01,\n",
       "         -2.37593547e-01, -4.47979301e-01, -8.65355670e-01,\n",
       "          7.65121281e-01, -9.90383327e-01,  3.82324457e-01,\n",
       "          6.48539364e-01,  2.66881108e-01, -3.27811688e-01,\n",
       "          7.71422923e-01, -1.29253045e-01, -3.89292866e-01,\n",
       "          6.93512186e-02, -8.94340396e-01, -9.60046291e-01,\n",
       "          3.71892065e-01,  9.99563336e-01, -3.90957855e-02,\n",
       "         -4.88997817e-01,  9.90934789e-01, -2.67010957e-01,\n",
       "          9.82963204e-01,  8.56696844e-01,  9.99372423e-01,\n",
       "         -1.92579180e-01,  9.96981084e-01,  2.10357442e-01,\n",
       "          2.84461647e-01,  9.65796486e-02,  2.44745061e-01,\n",
       "          9.76513445e-01,  4.05047178e-01, -6.81259751e-01,\n",
       "         -1.93609908e-01, -4.84825373e-01,  2.30696306e-01,\n",
       "         -9.99203742e-01, -9.56096470e-01, -5.79378188e-01,\n",
       "         -3.96878719e-02, -5.73904365e-02, -9.74193513e-01,\n",
       "         -9.73427594e-01,  1.00152403e-01,  2.40723401e-01,\n",
       "          1.62927836e-01,  2.42329016e-01,  9.43726182e-01,\n",
       "         -6.38530925e-02,  1.26870483e-01, -7.18344271e-01,\n",
       "         -9.92574334e-01, -7.11851195e-02, -1.46030426e-01,\n",
       "         -4.83590335e-01, -6.13327205e-01,  7.13953257e-01,\n",
       "         -1.53984979e-01, -9.97635901e-01,  2.99064964e-01,\n",
       "          9.98741150e-01,  8.56169045e-01,  3.11263293e-01,\n",
       "         -4.50186342e-01,  9.73553658e-01, -2.72070616e-01,\n",
       "         -1.30773008e-01,  9.94025409e-01, -9.99943256e-01,\n",
       "         -8.85474831e-02, -3.88364613e-01, -8.56459066e-02,\n",
       "          1.23220183e-01, -4.03664529e-01,  9.99085486e-01,\n",
       "          2.30332427e-02, -4.24665600e-01, -9.42262888e-01,\n",
       "          3.93936455e-01, -1.33290095e-02,  9.59551990e-01,\n",
       "          1.57274175e-02, -9.25130963e-01, -1.93071008e-01,\n",
       "         -2.65474349e-01, -9.99908507e-01,  9.78813648e-01,\n",
       "          4.50990796e-01, -9.99000013e-01,  2.61028677e-01,\n",
       "         -6.55636370e-01,  5.67904711e-01,  1.85161486e-01,\n",
       "         -9.02370572e-01, -1.27932683e-01, -9.99364913e-01,\n",
       "         -4.35874581e-01,  9.97788668e-01, -3.16906035e-01,\n",
       "          9.62255776e-01,  2.90363550e-01, -9.50056553e-01,\n",
       "         -2.74001718e-01, -1.88334510e-02,  2.15329662e-01,\n",
       "          2.70551324e-01,  4.60419685e-01, -9.78495777e-01,\n",
       "          9.95513856e-01, -9.37972844e-01,  7.95150578e-01,\n",
       "          1.82261333e-01, -8.90303075e-01, -8.80954564e-01,\n",
       "         -3.77923965e-01,  7.56195188e-02, -3.23663235e-01,\n",
       "         -9.85925734e-01, -9.98959482e-01, -6.33480623e-02,\n",
       "         -9.98691916e-01, -8.01522672e-01, -9.85162437e-01,\n",
       "          2.47793660e-01, -4.02586132e-01,  1.03882305e-01,\n",
       "         -1.52591825e-01,  2.09507987e-01,  2.19178610e-02,\n",
       "          5.76247633e-01,  1.60194486e-01,  9.98519659e-01,\n",
       "         -4.26371694e-01, -2.99708366e-01, -3.94284010e-01,\n",
       "          9.93945837e-01,  8.77698898e-01,  1.11086354e-01,\n",
       "         -9.98374939e-01,  4.53648925e-01,  9.91885662e-01,\n",
       "          9.16699469e-01,  8.71488273e-01,  9.96536732e-01,\n",
       "         -9.29224253e-01, -1.06886543e-01,  3.26357573e-01,\n",
       "         -5.76192617e-01,  7.50882268e-01, -1.37595713e-01,\n",
       "          6.93647325e-01, -9.98303115e-01, -9.70150948e-01,\n",
       "         -3.42495926e-02, -9.87183750e-01,  9.42197144e-01,\n",
       "          3.47525597e-01,  2.69227415e-01,  4.51329857e-01,\n",
       "          3.19435328e-01, -2.51565367e-01, -8.42267096e-01,\n",
       "         -9.86535668e-01, -6.13613486e-01,  1.50642574e-01,\n",
       "         -3.69367182e-01, -1.50070548e-01, -9.99991119e-01,\n",
       "         -9.76706386e-01,  4.00266826e-01,  2.16104940e-01,\n",
       "          2.96440069e-02, -5.82243800e-02,  2.13437140e-01,\n",
       "         -8.18849206e-01,  9.99166787e-01, -8.80628645e-01,\n",
       "         -1.37993604e-01,  3.45505252e-02,  7.73416236e-02,\n",
       "          6.84458688e-02, -1.80267736e-01,  9.59138155e-01,\n",
       "          7.51162827e-01,  1.32814333e-01,  2.18579829e-01,\n",
       "         -4.58394796e-01, -2.02126484e-02]], dtype=float32)>,\n",
       " 'sequence_output': <tf.Tensor: shape=(1, 128, 512), dtype=float32, numpy=\n",
       " array([[[-0.28946355,  0.34321266,  0.33231547, ...,  0.2130081 ,\n",
       "           0.71020746, -0.05771154],\n",
       "         [-0.28742057,  0.31980976, -0.23018584, ...,  0.5845509 ,\n",
       "          -0.21329743,  0.7269206 ],\n",
       "         [-0.6615704 ,  0.68876845, -0.87433034, ...,  0.10877228,\n",
       "          -0.2617323 ,  0.47855324],\n",
       "         ...,\n",
       "         [ 0.07634872, -0.14029235, -0.23991854, ...,  0.43109876,\n",
       "           0.91326904,  0.21486592],\n",
       "         [-0.44950593, -0.41251945, -0.1845075 , ...,  0.4268319 ,\n",
       "           0.5765461 ,  0.58352387],\n",
       "         [-1.0125369 , -0.86389136,  0.05829393, ...,  0.33312067,\n",
       "           0.36520985,  0.9429179 ]]], dtype=float32)>,\n",
       " 'encoder_outputs': [<tf.Tensor: shape=(1, 128, 512), dtype=float32, numpy=\n",
       "  array([[[-0.06295863, -0.11105272, -0.09978338, ..., -0.6856478 ,\n",
       "           -0.00407175, -0.11052184],\n",
       "          [-1.2244794 ,  0.47480857,  1.4847255 , ...,  0.18143621,\n",
       "           -0.070593  ,  0.51479703],\n",
       "          [-0.14552249,  0.69274646,  0.25901467, ..., -0.24963437,\n",
       "            0.31400165,  0.10638109],\n",
       "          ...,\n",
       "          [ 0.19391039, -1.0414373 ,  0.13234231, ...,  0.48335594,\n",
       "            0.05794983,  0.69196856],\n",
       "          [ 0.41838217, -1.4511168 ,  0.45226434, ...,  0.53969014,\n",
       "           -0.27019352,  0.7139552 ],\n",
       "          [ 0.8272978 , -1.2287501 ,  0.76959425, ...,  0.362437  ,\n",
       "            0.50261414,  0.5086677 ]]], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(1, 128, 512), dtype=float32, numpy=\n",
       "  array([[[-0.06680907,  0.6666775 , -0.57858765, ...,  0.05077539,\n",
       "            0.33134192, -0.38221192],\n",
       "          [-1.1505064 ,  0.8133267 ,  0.6916461 , ...,  0.85625106,\n",
       "           -0.15926126,  0.3378436 ],\n",
       "          [-0.56601083,  1.2607758 ,  0.0207469 , ...,  0.18951696,\n",
       "           -0.2877145 ,  0.27875507],\n",
       "          ...,\n",
       "          [ 0.12957165, -0.25208497, -0.2880355 , ...,  0.6268495 ,\n",
       "            0.26911458,  0.3792309 ],\n",
       "          [-0.01897656, -0.26435336,  0.025655  , ...,  0.89059377,\n",
       "           -0.04837482,  0.5159347 ],\n",
       "          [ 0.03458991, -0.2503766 ,  0.16714852, ...,  0.7022622 ,\n",
       "            0.52254754,  0.29193896]]], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(1, 128, 512), dtype=float32, numpy=\n",
       "  array([[[-0.5085996 ,  0.587828  , -0.23816352, ...,  0.11439952,\n",
       "            0.14917368,  0.02905509],\n",
       "          [-0.92587316,  0.5011992 ,  0.45877105, ...,  0.9532699 ,\n",
       "           -0.24297133,  0.74963105],\n",
       "          [-0.88641346,  0.85034364, -0.5377838 , ...,  0.22808081,\n",
       "           -0.40447333,  0.2239269 ],\n",
       "          ...,\n",
       "          [ 0.32143724, -0.17559439, -0.36333284, ...,  0.803551  ,\n",
       "           -0.07853526,  0.244928  ],\n",
       "          [-0.4245719 , -0.57410127, -0.12558872, ...,  0.7957445 ,\n",
       "           -0.15693244,  0.54348844],\n",
       "          [-0.91434956, -0.57436967, -0.12035415, ...,  0.9594733 ,\n",
       "            0.14524904,  0.7741571 ]]], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(1, 128, 512), dtype=float32, numpy=\n",
       "  array([[[-0.28946355,  0.34321266,  0.33231547, ...,  0.2130081 ,\n",
       "            0.71020746, -0.05771154],\n",
       "          [-0.28742057,  0.31980976, -0.23018584, ...,  0.5845509 ,\n",
       "           -0.21329743,  0.7269206 ],\n",
       "          [-0.6615704 ,  0.68876845, -0.87433034, ...,  0.10877228,\n",
       "           -0.2617323 ,  0.47855324],\n",
       "          ...,\n",
       "          [ 0.07634872, -0.14029235, -0.23991854, ...,  0.43109876,\n",
       "            0.91326904,  0.21486592],\n",
       "          [-0.44950593, -0.41251945, -0.1845075 , ...,  0.4268319 ,\n",
       "            0.5765461 ,  0.58352387],\n",
       "          [-1.0125369 , -0.86389136,  0.05829393, ...,  0.33312067,\n",
       "            0.36520985,  0.9429179 ]]], dtype=float32)>]}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model(text_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier_model():\n",
    "    \n",
    "  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "  preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
    "  encoder_inputs = preprocessing_layer(text_input)\n",
    "  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
    "  outputs = encoder(encoder_inputs)\n",
    "  net = outputs['pooled_output']\n",
    "  net = tf.keras.layers.Dropout(0.1)(net)\n",
    "  net = tf.keras.layers.Dense(1, activation=None, name='classifier')(net)\n",
    "  return tf.keras.Model(text_input, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.53225774]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "classifier_model = build_classifier_model()\n",
    "bert_raw_result = classifier_model(tf.constant(text_test))\n",
    "print(tf.sigmoid(bert_raw_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "metrics = tf.metrics.BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'optimization'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [67]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m      3\u001b[0m init_lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3e-5\u001b[39m\n\u001b[1;32m----> 4\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimization\u001b[49m\u001b[38;5;241m.\u001b[39mcreate_optimizer(init_lr\u001b[38;5;241m=\u001b[39minit_lr,\n\u001b[0;32m      5\u001b[0m                                           optimizer_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madamw\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'optimization'"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "init_lr = 3e-5\n",
    "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
    "                                          optimizer_type='adamw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
